# ğŸ§  ClassificaÃ§Ã£o: ValidaÃ§Ã£o de Modelos e MÃ©tricas de AvaliaÃ§Ã£o

Este projeto foi desenvolvido como parte do curso **"ClassificaÃ§Ã£o: validaÃ§Ã£o de modelos e mÃ©tricas de avaliaÃ§Ã£o"**. O foco principal Ã© aplicar tÃ©cnicas de avaliaÃ§Ã£o e validaÃ§Ã£o de modelos de classificaÃ§Ã£o utilizando bibliotecas do ecossistema Python voltadas para ciÃªncia de dados e machine learning.

## ğŸ“Œ Objetivos

- Avaliar o desempenho de modelos preditivos de classificaÃ§Ã£o.
- Aplicar tÃ©cnicas de validaÃ§Ã£o cruzada para obter mÃ©tricas mais confiÃ¡veis.
- Trabalhar com dados desbalanceados utilizando tÃ©cnicas de oversampling e undersampling.
- Interpretar mÃ©tricas como *precision*, *recall*, *f1-score*, *ROC AUC*, entre outras.
- Visualizar e comparar o desempenho dos modelos com diferentes abordagens.

## ğŸ› ï¸ Tecnologias e Bibliotecas

- `pandas` para manipulaÃ§Ã£o de dados
- `scikit-learn` para criaÃ§Ã£o de modelos e mÃ©tricas:
  - `DecisionTreeClassifier`
  - `train_test_split`
  - `confusion_matrix`, `ConfusionMatrixDisplay`
  - `precision_score`, `recall_score`, `accuracy_score`, `f1_score`
  - `roc_auc_score`, `RocCurveDisplay`, `PrecisionRecallDisplay`
  - `classification_report`
  - `cross_validate`, `KFold`, `StratifiedKFold`
- `imblearn` para balanceamento de classes:
  - `SMOTE` (oversampling)
  - `NearMiss` (undersampling)
  - `Pipeline` para integrar os passos de forma eficiente

## ğŸ“Š O que foi feito

1. **PrÃ©-processamento de dados**  
   Limpeza, tratamento e divisÃ£o entre treino e teste.

2. **CriaÃ§Ã£o do modelo base**  
   Modelo de Ã¡rvore de decisÃ£o (`DecisionTreeClassifier`) como baseline.

3. **ValidaÃ§Ã£o cruzada**  
   AplicaÃ§Ã£o de validaÃ§Ã£o com `KFold` e `StratifiedKFold` para maior robustez na anÃ¡lise.

4. **Balanceamento das classes**  
   Uso de `SMOTE` e `NearMiss` em conjunto com `Pipeline` para combater o desbalanceamento.

5. **AvaliaÃ§Ã£o do modelo**  
   AnÃ¡lise com diversas mÃ©tricas e visualizaÃ§Ãµes para entender o desempenho e os trade-offs.

6. **ComparaÃ§Ã£o de abordagens**  
   AvaliaÃ§Ã£o dos impactos de diferentes tÃ©cnicas de balanceamento e validaÃ§Ã£o no resultado final.

## ğŸ“ˆ Resultados

- MÃ©tricas detalhadas como precisÃ£o, recall, f1-score e ROC AUC.
- RelatÃ³rios completos gerados com `classification_report`.
- VisualizaÃ§Ãµes para facilitar a interpretaÃ§Ã£o dos resultados.

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ dados/                     # Dados utilizados (ou link para obtÃª-los)
â”œâ”€â”€ notebooks/                 # Notebooks com as anÃ¡lises
â”œâ”€â”€ imagens/                   # GrÃ¡ficos gerados
â”œâ”€â”€ requirements.txt           # Bibliotecas necessÃ¡rias
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ“ Como executar

1. Clone este repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

3. Rode o notebook principal no Jupyter, VSCode ou Google Colab.

---

## ğŸ§  Autor

Feito por Gabriel Butti como parte dos estudos em Machine Learning.  
Conecte-se comigo no [LinkedIn][(https://www.linkedin.com/in/seu-perfil](https://www.linkedin.com/in/gabriel-butti-393bb1179/)).
